{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f300fd14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Visualization\n",
    "# BTech Computer Science Stream , January 2025\n",
    "# Week 5 Data Cleaning and Preparation  - Demonstration Code\n",
    "# Name: Divyansh Garg , reg number - 240953118 , Date: 10/02/2025"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ecac61cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "335e1db6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>movie_name</th>\n",
       "      <th>language</th>\n",
       "      <th>genre</th>\n",
       "      <th>rating</th>\n",
       "      <th>review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Titanic</td>\n",
       "      <td>English</td>\n",
       "      <td>Romance</td>\n",
       "      <td>7.8</td>\n",
       "      <td>Epic love story</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The Dark Knight</td>\n",
       "      <td>English</td>\n",
       "      <td>Action</td>\n",
       "      <td>9.0</td>\n",
       "      <td>Legendary crime drama</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Avatar</td>\n",
       "      <td>English</td>\n",
       "      <td>Action</td>\n",
       "      <td>7.8</td>\n",
       "      <td>Visual masterpiece</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The Godfather</td>\n",
       "      <td>English</td>\n",
       "      <td>Crime</td>\n",
       "      <td>9.2</td>\n",
       "      <td>Masterpiece of crime and drama</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Shawshank Redemption</td>\n",
       "      <td>English</td>\n",
       "      <td>Drama</td>\n",
       "      <td>9.3</td>\n",
       "      <td>Inspirational prison drama</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>The Matrix</td>\n",
       "      <td>English</td>\n",
       "      <td>Sci-Fi</td>\n",
       "      <td>8.7</td>\n",
       "      <td>Groundbreaking sci-fi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Interstellar</td>\n",
       "      <td>English</td>\n",
       "      <td>Adventure</td>\n",
       "      <td>8.6</td>\n",
       "      <td>Emotional and thought-provoking</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Gladiator</td>\n",
       "      <td>English</td>\n",
       "      <td>Action</td>\n",
       "      <td>8.5</td>\n",
       "      <td>Epic and heroic story</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Forrest Gump</td>\n",
       "      <td>English</td>\n",
       "      <td>Drama</td>\n",
       "      <td>8.8</td>\n",
       "      <td>Life-affirming journey</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>golmal</td>\n",
       "      <td>Hindi</td>\n",
       "      <td>Comedy</td>\n",
       "      <td>9.5</td>\n",
       "      <td>fun watch</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             movie_name language      genre  rating  \\\n",
       "0               Titanic  English    Romance     7.8   \n",
       "1       The Dark Knight  English     Action     9.0   \n",
       "2                Avatar  English     Action     7.8   \n",
       "3         The Godfather  English      Crime     9.2   \n",
       "4  Shawshank Redemption  English      Drama     9.3   \n",
       "5            The Matrix  English     Sci-Fi     8.7   \n",
       "6          Interstellar  English  Adventure     8.6   \n",
       "7             Gladiator  English     Action     8.5   \n",
       "8          Forrest Gump  English      Drama     8.8   \n",
       "9                golmal    Hindi     Comedy     9.5   \n",
       "\n",
       "                            review  \n",
       "0                  Epic love story  \n",
       "1            Legendary crime drama  \n",
       "2               Visual masterpiece  \n",
       "3   Masterpiece of crime and drama  \n",
       "4       Inspirational prison drama  \n",
       "5            Groundbreaking sci-fi  \n",
       "6  Emotional and thought-provoking  \n",
       "7            Epic and heroic story  \n",
       "8           Life-affirming journey  \n",
       "9                        fun watch  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"Movies.csv\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a3246209",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Highest rated movie is:  movie_name       golmal\n",
      "language          Hindi\n",
      "genre            Comedy\n",
      "rating              9.5\n",
      "review        fun watch\n",
      "Name: 9, dtype: object\n",
      "The movie with the highest rating is:\n",
      "movie_name       golmal\n",
      "language          Hindi\n",
      "genre            Comedy\n",
      "rating              9.5\n",
      "review        fun watch\n",
      "Name: 9, dtype: object\n",
      "Hindi Movies saved to: HindiMovies.csv\n"
     ]
    }
   ],
   "source": [
    "highest_rated_movie = df.loc[df['rating'].idxmax()]\n",
    "print(\"Highest rated movie is: \",highest_rated_movie)\n",
    "df_hindi_movies = df[df['language'] == 'Hindi']\n",
    "hindi_movies_file_path = \"HindiMovies.csv\"\n",
    "df_hindi_movies.to_csv(hindi_movies_file_path, index=False)\n",
    "\n",
    "print(f\"The movie with the highest rating is:\\n{highest_rated_movie}\")\n",
    "print(f\"Hindi Movies saved to: {hindi_movies_file_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "796f2744",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question 2\n"
     ]
    }
   ],
   "source": [
    "print(\"Question 2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "536cdc9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial 5-Number Summary:\n",
      "         calories    protein        fat      sodium      fiber    vitamins  \\\n",
      "count   76.000000  76.000000  76.000000   76.000000  76.000000   76.000000   \n",
      "mean   107.368421   2.526316   1.013158  160.065789   2.048684   28.289474   \n",
      "std     19.139378   1.089020   1.013159   84.318813   2.219038   22.487813   \n",
      "min     50.000000   1.000000   0.000000    0.000000   0.000000    0.000000   \n",
      "25%    100.000000   2.000000   0.000000  132.500000   0.750000   25.000000   \n",
      "50%    110.000000   2.500000   1.000000  180.000000   1.750000   25.000000   \n",
      "75%    110.000000   3.000000   2.000000  212.500000   3.000000   25.000000   \n",
      "max    160.000000   6.000000   5.000000  320.000000  14.000000  100.000000   \n",
      "\n",
      "           shelf     weight       cups     rating  \n",
      "count  76.000000  76.000000  76.000000  76.000000  \n",
      "mean    2.197368   1.030000   0.827500  42.327057  \n",
      "std     0.832982   0.151438   0.227204  13.820602  \n",
      "min     1.000000   0.500000   0.250000  18.042851  \n",
      "25%     1.000000   1.000000   0.670000  32.932466  \n",
      "50%     2.000000   1.000000   0.750000  40.253086  \n",
      "75%     3.000000   1.000000   1.000000  50.780847  \n",
      "max     3.000000   1.500000   1.500000  93.704912  \n",
      "\n",
      "5-Number Summary (After Missing Value Treatment):\n",
      "         calories    protein        fat      sodium      fiber    vitamins  \\\n",
      "count   76.000000  76.000000  76.000000   76.000000  76.000000   76.000000   \n",
      "mean   107.368421   2.526316   1.013158  160.065789   2.048684   28.289474   \n",
      "std     19.139378   1.089020   1.013159   84.318813   2.219038   22.487813   \n",
      "min     50.000000   1.000000   0.000000    0.000000   0.000000    0.000000   \n",
      "25%    100.000000   2.000000   0.000000  132.500000   0.750000   25.000000   \n",
      "50%    110.000000   2.500000   1.000000  180.000000   1.750000   25.000000   \n",
      "75%    110.000000   3.000000   2.000000  212.500000   3.000000   25.000000   \n",
      "max    160.000000   6.000000   5.000000  320.000000  14.000000  100.000000   \n",
      "\n",
      "           shelf     weight       cups     rating  \n",
      "count  76.000000  76.000000  76.000000  76.000000  \n",
      "mean    2.197368   1.030000   0.827500  42.327057  \n",
      "std     0.832982   0.151438   0.227204  13.820602  \n",
      "min     1.000000   0.500000   0.250000  18.042851  \n",
      "25%     1.000000   1.000000   0.670000  32.932466  \n",
      "50%     2.000000   1.000000   0.750000  40.253086  \n",
      "75%     3.000000   1.000000   1.000000  50.780847  \n",
      "max     3.000000   1.500000   1.500000  93.704912  \n",
      "\n",
      "Effectiveness of Missing Value Treatment:\n",
      "Replacing missing values with the mean can be effective if the data is missing at random (MAR) and the missing values are not a large proportion of the dataset.  It helps preserve the overall distribution of the data to some extent.  However, if the missing data is not MAR or if there are many missing values, this strategy may introduce bias. In this case, since we are replacing -1, which likely represents a true 0 value, this strategy is not completely accurate. A better approach would be to replace -1 with 0.\n",
      "Replaced outliers in 'calories' with median: 110.0\n",
      "Replaced outliers in 'protein' with median: 2.5\n",
      "Replaced outliers in 'fat' with median: 1.0\n",
      "Replaced outliers in 'sodium' with median: 180.0\n",
      "Replaced outliers in 'fiber' with median: 1.75\n",
      "Replaced outliers in 'vitamins' with median: 25.0\n",
      "Replaced outliers in 'shelf' with median: 2.0\n",
      "Replaced outliers in 'weight' with median: 1.0\n",
      "Replaced outliers in 'cups' with median: 0.75\n",
      "Replaced outliers in 'rating' with median: 40.253086499999995\n",
      "\n",
      "5-Number Summary (After Noisy Value Treatment):\n",
      "         calories    protein        fat      sodium      fiber  vitamins  \\\n",
      "count   76.000000  76.000000  76.000000   76.000000  76.000000      76.0   \n",
      "mean   107.236842   2.401316   1.013158  181.381579   1.792105      25.0   \n",
      "std      8.099166   0.875670   1.013159   60.186370   1.520220       0.0   \n",
      "min     90.000000   1.000000   0.000000   15.000000   0.000000      25.0   \n",
      "25%    100.000000   2.000000   0.000000  147.500000   0.750000      25.0   \n",
      "50%    110.000000   2.250000   1.000000  180.000000   1.625000      25.0   \n",
      "75%    110.000000   3.000000   2.000000  212.500000   3.000000      25.0   \n",
      "max    120.000000   4.000000   5.000000  320.000000   6.000000      25.0   \n",
      "\n",
      "           shelf  weight       cups     rating  \n",
      "count  76.000000    76.0  76.000000  76.000000  \n",
      "mean    2.197368     1.0   0.817632  41.623743  \n",
      "std     0.832982     0.0   0.213478  12.464724  \n",
      "min     1.000000     1.0   0.250000  18.042851  \n",
      "25%     1.000000     1.0   0.670000  32.932466  \n",
      "50%     2.000000     1.0   0.750000  40.179526  \n",
      "75%     3.000000     1.0   1.000000  50.031833  \n",
      "max     3.000000     1.0   1.330000  74.472949  \n",
      "\n",
      "Effectiveness of Noisy Value Treatment:\n",
      "Replacing outliers with the median is a robust method for handling noisy data. It reduces the impact of extreme values without significantly altering the central tendency of the data.  It is generally effective when the data contains outliers due to measurement errors or other anomalies. However, it can mask truly extreme values if they are valid data points. We used the IQR method to identify outliers. Other methods could be used such as the standard deviation method.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Load the CEREALS dataset (replace 'cereals.csv' with the actual path)\n",
    "try:\n",
    "    cereals = pd.read_csv('cereals.csv')\n",
    "except FileNotFoundError:\n",
    "    print(\"Error: cereals.csv not found. Please provide the correct path.\")\n",
    "    exit()  # Exit the script if the file is not found\n",
    "\n",
    "# a. 5-Number Summary (Initial)\n",
    "print(\"Initial 5-Number Summary:\")\n",
    "print(cereals.describe())\n",
    "\n",
    "# b. Replace Missing Values with Mean\n",
    "numeric_cols = cereals.columns[cereals.dtypes != 'object']  # Select numeric columns\n",
    "for col in numeric_cols:\n",
    "    if -1 in cereals[col].values:  # Check if -1 exists in the column\n",
    "        mean_val = cereals[col][cereals[col] != -1].mean() #Calculate mean excluding -1\n",
    "        cereals[col] = cereals[col].replace(-1, mean_val)\n",
    "        print(f\"Replaced missing values in '{col}' with mean: {mean_val}\")\n",
    "\n",
    "\n",
    "# c. 5-Number Summary (After Missing Value Treatment)\n",
    "print(\"\\n5-Number Summary (After Missing Value Treatment):\")\n",
    "print(cereals.describe())\n",
    "\n",
    "# Effectiveness of Missing Value Treatment:\n",
    "print(\"\\nEffectiveness of Missing Value Treatment:\")\n",
    "print(\"Replacing missing values with the mean can be effective if the data is missing at random (MAR) and the missing values are not a large proportion of the dataset.  It helps preserve the overall distribution of the data to some extent.  However, if the missing data is not MAR or if there are many missing values, this strategy may introduce bias. In this case, since we are replacing -1, which likely represents a true 0 value, this strategy is not completely accurate. A better approach would be to replace -1 with 0.\")\n",
    "\n",
    "\n",
    "# d. Replace Noisy Data with Median\n",
    "def replace_outliers(df, col):\n",
    "    Q1 = df[col].quantile(0.25)\n",
    "    Q3 = df[col].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    lower_bound = Q1 - 1.5 * IQR\n",
    "    upper_bound = Q3 + 1.5 * IQR\n",
    "    median_val = df[col].median()\n",
    "    df[col] = np.where((df[col] < lower_bound) | (df[col] > upper_bound), median_val, df[col])\n",
    "    print(f\"Replaced outliers in '{col}' with median: {median_val}\")\n",
    "    return df\n",
    "\n",
    "for col in numeric_cols:\n",
    "    cereals = replace_outliers(cereals, col)\n",
    "\n",
    "\n",
    "# e. 5-Number Summary (After Noisy Value Treatment)\n",
    "print(\"\\n5-Number Summary (After Noisy Value Treatment):\")\n",
    "print(cereals.describe())\n",
    "\n",
    "# Effectiveness of Noisy Value Treatment:\n",
    "print(\"\\nEffectiveness of Noisy Value Treatment:\")\n",
    "print(\"Replacing outliers with the median is a robust method for handling noisy data. It reduces the impact of extreme values without significantly altering the central tendency of the data.  It is generally effective when the data contains outliers due to measurement errors or other anomalies. However, it can mask truly extreme values if they are valid data points. We used the IQR method to identify outliers. Other methods could be used such as the standard deviation method.\")\n",
    "\n",
    "\n",
    "# Display the updated DataFrame (optional)\n",
    "#print(\"\\nUpdated DataFrame:\")\n",
    "#print(cereals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e9c0032",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
